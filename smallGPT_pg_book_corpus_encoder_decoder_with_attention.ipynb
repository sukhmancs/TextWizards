{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMUlTb+sNnTRjoRB89lGpVr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sukhmancs/TextWizards/blob/main/smallGPT_pg_book_corpus_encoder_decoder_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#✋ **_Note:_**\n",
        "- **MAX_LENGTH must be equal to the target_len.**\n",
        "- **The cells that are testing the code will going to throw `runtime` error while using GPU. (Because the tensors are not on the same device). Stick with CPU to test the code 🌝.**"
      ],
      "metadata": {
        "id": "Xob-BL_2T8Gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install LangChain"
      ],
      "metadata": {
        "id": "j7_u2a3QMIKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "s8GUcGTDbl4O"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install chromadb==0.4.10 tiktoken==0.3.3 sqlalchemy==2.0.15\n",
        "!pip install langchain==0.0.249\n",
        "#!pip install --force-reinstall pydantic==1.10.6\n",
        "#!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "BaPotns5Vw9-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab040e2c-5fb9-4e6b-ce59-a2ca278e2e56"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain==0.0.249 in /usr/local/lib/python3.10/dist-packages (0.0.249)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (0.0.83)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (2.8.8)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (1.23.5)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.249) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.249) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.249) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.249) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.249) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.249) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.249) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.249) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.249) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.249) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.249) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.249) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.249) (2023.11.17)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.249) (3.0.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.249) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.249) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import modules and Download data"
      ],
      "metadata": {
        "id": "Q1Ww3lfZjNF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "DZlXhowrVhY7"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, ConversationalRetrievalChain, ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.schema import messages_from_dict, messages_to_dict\n",
        "from langchain.memory.chat_message_histories.in_memory import ChatMessageHistory\n",
        "from langchain.agents import Tool\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import GutenbergLoader\n",
        "\n",
        "loader = GutenbergLoader(\n",
        "    \"https://www.gutenberg.org/cache/epub/100/pg100.txt\"\n",
        ")\n",
        "\n",
        "document = loader.load()\n",
        "\n",
        "extrait = ' '.join(document[0].page_content.split()[:100])\n",
        "display(extrait + \" .......\")\n",
        "\n"
      ],
      "metadata": {
        "id": "6NqLHt0yV3PQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "2adca0b8-cb43-4bc9-8c11-5396089c406f"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The Project Gutenberg eBook of The Complete Works of William Shakespeare This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this ebook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook. Title: The Complete Works of William Shakespeare .......'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = ' '.join(document[0].page_content.split())"
      ],
      "metadata": {
        "id": "L298xL6FbYgS"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset, RandomSampler\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random"
      ],
      "metadata": {
        "id": "unFkoAxNfiUL"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "WaBW4U6xjI7z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "fBB4zRME3KzL"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        # To Do: Add normalizeString() function in here to to normalize the sentence (i.e. data)\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    # To Do: Define normalizeString() function in here\n",
        "    def normalizeString(s):\n",
        "        # Start code\n",
        "        pass\n",
        "        # End code\n",
        "\n",
        "    # To Do: Define unicodeToAscii(s) function in here\n",
        "    def unicodeToAscii(s):\n",
        "        # Start code\n",
        "        pass\n",
        "        # End code\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "p71SzQiJ3rLN"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "-53sCMxTNOWC"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lang = Lang()\n",
        "lang.addSentence(data)\n",
        "encode = lambda s: [lang.word2index[word] for word in s.split(' ')] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ' '.join([lang.index2word[i] for i in l]) # decoder: take a list of integers, output a string"
      ],
      "metadata": {
        "id": "psaW9lOlgmO3"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encode(\"what values are available\"))\n",
        "print(decode(encode(\"what values are available\")))"
      ],
      "metadata": {
        "id": "YParNcFji98H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3773ce12-32a7-4940-eb4e-d12c8a599fb9"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[508, 20726, 52, 71246]\n",
            "what values are available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "data = torch.tensor(encode(data), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:300]) # the 300 characters we looked at earier will to the GPT look like this"
      ],
      "metadata": {
        "id": "u11Xb_CujxIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8953d39d-6744-4121-d806-32c6f37adbcd"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([966501]) torch.int64\n",
            "tensor([  2,   3,   4,   5,   6,   2,   7,   8,   6,   9,  10,  11,  12,  13,\n",
            "         14,  15,  16,   6,  17,  18,  19,  15,  20,  21,  22,  23,  24,  25,\n",
            "          6,  15,  26,  27,  28,  29,  22,  30,  31,  28,  32,  33,  34,  35,\n",
            "         36,  37,  38,  39,  40,  41,  42,  39,  43,  15,  44,   6,  15,   3,\n",
            "          4,  45,  46,  30,  47,  12,  41,  48,  27,  49,  50,  51,  52,  53,\n",
            "         54,  19,  15,  20,  55,  51,  56,  57,  58,  59,  15,  60,   6,  15,\n",
            "         61,  62,  51,  52,  54,  63,  64,  47,  65,  66,   2,   7,   8,   6,\n",
            "          9,  10,  67,   9,  10,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
            "         77,  70,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  85,\n",
            "         89,  90,  84,  91,  92,  82,   2,   7,   8,   6,   9,  10,  93,   9,\n",
            "         10,  94,  85,  95,  96,  97,  98,  99,  97,  85, 100,  84, 101, 102,\n",
            "        103, 104, 105, 106, 107,  85, 108,  84, 109,  85, 100,  84, 110, 111,\n",
            "         85, 100,  84, 112, 113,  84, 114,  85, 115, 116,  84, 117, 118,  85,\n",
            "        119,  85, 120, 116,  84, 117, 118,  85, 119,  85, 121,  84, 117, 118,\n",
            "         85, 122,  85, 115, 116,  84, 118,  85, 123,  85, 120, 116,  84, 117,\n",
            "        118,  85, 123,  85, 124, 116,  84, 117, 118,  85, 123, 117, 118,  85,\n",
            "        125,  85, 121, 102, 126,  84, 117, 127,  85, 100,  84, 128, 129,  85,\n",
            "        100,  84, 117, 130, 131, 132, 133,  85, 100,  84, 134, 135, 136, 135,\n",
            "         85, 137,  84, 138,  85, 139, 140,  84, 141, 142, 143, 144, 145, 146,\n",
            "        147, 148, 149,  85, 100,  84, 150,  85, 151,  84, 138, 152, 113,  84,\n",
            "        153, 117, 154,  85, 120, 117, 154,  85, 124,  85, 100,  84, 155, 102,\n",
            "        156,  85, 157,  84,  85, 158])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "8vD9wPC7kubp"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "id": "xEfMDDsTkftq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3ce8544-2a98-4a4b-9b03-d5708cda3390"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([2]) the target: 3\n",
            "when input is tensor([2, 3]) the target: 4\n",
            "when input is tensor([2, 3, 4]) the target: 5\n",
            "when input is tensor([2, 3, 4, 5]) the target: 6\n",
            "when input is tensor([2, 3, 4, 5, 6]) the target: 2\n",
            "when input is tensor([2, 3, 4, 5, 6, 2]) the target: 7\n",
            "when input is tensor([2, 3, 4, 5, 6, 2, 7]) the target: 8\n",
            "when input is tensor([2, 3, 4, 5, 6, 2, 7, 8]) the target: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "VRtnxmuqz2rq"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lang.n_words * 0.05"
      ],
      "metadata": {
        "id": "2h1AwLPIb7i2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e4c10a8-edb6-4a85-8256-4527cf912010"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3579.8"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "sZeORww3z2rr"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "n_words = lang.n_words\n",
        "\n",
        "def get_batch(split, batch_size):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    # How many sentences i want to make out of ~71k words\n",
        "    # Increase this value to train on a larger data (i.e. more number of sentences)\n",
        "    ix = torch.randint(len(data) - MAX_LENGTH, (int(n_words * 0.05),))\n",
        "    x = torch.stack([data[i:i+MAX_LENGTH] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+MAX_LENGTH+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "def get_dataloader(batch_size, split='train'):\n",
        "    print(\"Parsing data...\")\n",
        "    input_ids, target_ids = get_batch(split, batch_size)\n",
        "    print(f\"input_ids length: {len(input_ids)}, target_ids length: {len(target_ids)}\")\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return train_dataloader\n",
        "\n",
        "xb, yb = get_batch('train', batch_size)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "id": "T2Wsl0v3k5Mh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fd44dcf-3cc7-4b5a-e238-a226aa931fa2"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([3579, 10])\n",
            "tensor([[ 2093,   244,   272,  ...,    58,   227, 41029],\n",
            "        [11783,    30, 15195,  ...,  3257,    58,   907],\n",
            "        [ 5177,    15, 44665,  ...,   288,   283, 12861],\n",
            "        ...,\n",
            "        [ 1871, 35235,   117,  ..., 28416,  7386,   764],\n",
            "        [61548,   371,  1080,  ...,  3316, 18563,    93],\n",
            "        [  272,  1061,   932,  ...,    58,    15,  2396]])\n",
            "targets:\n",
            "torch.Size([3579, 10])\n",
            "tensor([[  244,   272,   238,  ...,   227, 41029,  1162],\n",
            "        [   30, 15195, 53804,  ...,    58,   907,   908],\n",
            "        [   15, 44665, 44359,  ...,   283, 12861, 44640],\n",
            "        ...,\n",
            "        [35235,   117, 30761,  ...,  7386,   764,   570],\n",
            "        [  371,  1080,   297,  ..., 18563,    93,    22],\n",
            "        [ 1061,   932,  4853,  ...,    15,  2396,     6]])\n",
            "----\n",
            "when input is [2093] the target: 244\n",
            "when input is [2093, 244] the target: 272\n",
            "when input is [2093, 244, 272] the target: 238\n",
            "when input is [2093, 244, 272, 238] the target: 1300\n",
            "when input is [2093, 244, 272, 238, 1300] the target: 38\n",
            "when input is [2093, 244, 272, 238, 1300, 38] the target: 2485\n",
            "when input is [2093, 244, 272, 238, 1300, 38, 2485] the target: 58\n",
            "when input is [2093, 244, 272, 238, 1300, 38, 2485, 58] the target: 227\n",
            "when input is [11783] the target: 30\n",
            "when input is [11783, 30] the target: 15195\n",
            "when input is [11783, 30, 15195] the target: 53804\n",
            "when input is [11783, 30, 15195, 53804] the target: 34\n",
            "when input is [11783, 30, 15195, 53804, 34] the target: 57\n",
            "when input is [11783, 30, 15195, 53804, 34, 57] the target: 959\n",
            "when input is [11783, 30, 15195, 53804, 34, 57, 959] the target: 3257\n",
            "when input is [11783, 30, 15195, 53804, 34, 57, 959, 3257] the target: 58\n",
            "when input is [5177] the target: 15\n",
            "when input is [5177, 15] the target: 44665\n",
            "when input is [5177, 15, 44665] the target: 44359\n",
            "when input is [5177, 15, 44665, 44359] the target: 34\n",
            "when input is [5177, 15, 44665, 44359, 34] the target: 449\n",
            "when input is [5177, 15, 44665, 44359, 34, 449] the target: 53\n",
            "when input is [5177, 15, 44665, 44359, 34, 449, 53] the target: 288\n",
            "when input is [5177, 15, 44665, 44359, 34, 449, 53, 288] the target: 283\n",
            "when input is [19] the target: 385\n",
            "when input is [19, 385] the target: 12647\n",
            "when input is [19, 385, 12647] the target: 766\n",
            "when input is [19, 385, 12647, 766] the target: 4850\n",
            "when input is [19, 385, 12647, 766, 4850] the target: 203\n",
            "when input is [19, 385, 12647, 766, 4850, 203] the target: 13\n",
            "when input is [19, 385, 12647, 766, 4850, 203, 13] the target: 15\n",
            "when input is [19, 385, 12647, 766, 4850, 203, 13, 15] the target: 250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = get_dataloader(batch_size=32, split='train')\n",
        "\n",
        "for data in train_dataloader:\n",
        "    inputs, targets = data\n",
        "    print(inputs)\n",
        "    break\n",
        ""
      ],
      "metadata": {
        "id": "blzNNrPqzqCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f598d6a-1e06-4d3a-ce05-bf58f606c2c7"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing data...\n",
            "input_ids length: 3579, target_ids length: 3579\n",
            "tensor([[ 5160,   455,   259,  4808, 26845,  4466,   753, 10491,   483,    63],\n",
            "        [27855,    22, 57200,   115, 36115,   312,   434,   214,  4776,  5812],\n",
            "        [ 2587,   527,  4291,   238,   326,  1383, 26233, 10022,   288,    15],\n",
            "        [  326, 14112,    22,  3019, 62922, 45744,   202,  2485,   764,   233],\n",
            "        [49849,    22,    53,    58,  1305,   227, 49848,  1840,   866, 49850],\n",
            "        [ 2570, 18064, 17498,  5103,   372,    13, 18065,   753,  3063,    15],\n",
            "        [ 1901,   195,  7263,     6, 38577,    19, 12251,  1659,  1305,   212],\n",
            "        [  212,  8786,   334, 16593,    93,   221, 16821,   244,  3069,  3833],\n",
            "        [21737,   669, 24916,  6520,  4948, 39759, 15980,    51,  1342,  1897],\n",
            "        [11765,  4549, 23012,   694,   227,  5175,    58,    15,  1273,   362],\n",
            "        [  764, 11879,   753,   200,  7200,   227, 25015,   506,  5713,   227],\n",
            "        [15210, 51565,  1340,   516,   481,  7498,   719,  1466,    13,   240],\n",
            "        [  738,   283,  1115,   203,   753,  3062, 59507,  5415,   753,  6285],\n",
            "        [  214,  1305,   812,   326,  7986, 20242,  1588,   238,  1306,    58],\n",
            "        [ 2286,  5090, 53956, 53746,   244,  1316,   431,  3852,   238,    15],\n",
            "        [   43,   212,  4498,   372,  9292,    53,  5160,  5812,  3771,  6554],\n",
            "        [  192,    14,  1802,  5649,   285,   474,   608,  1162,  1383,     6],\n",
            "        [ 4888,     2,  2517,   142, 26100,    63,    15, 23030,  7529,    30],\n",
            "        [  244,    24,     6,   726, 48741, 16359,   195,  6634,    53,  1394],\n",
            "        [   56,   753,  4141,   533,   565,   238,    52,   221, 59134,  5103],\n",
            "        [    6,   385,  3392,  4853,  8855,  6553,   385, 22408,    22,  1533],\n",
            "        [  244,   440,   416,   221,  5831, 27837, 26132,  5591,   326,  5014],\n",
            "        [  142, 18102, 30621, 30622,  2622,     6,  8123, 30623,    15, 30624],\n",
            "        [ 7716,    22,   522,   866,  2043,    22,   340,  7067,  3666,  7119],\n",
            "        [37059,    51,   870,  1342,   440,  3782,    39,    13,    58,   288],\n",
            "        [  859,  3851,  3519,   444,  1981, 14119, 28668,  6805,    15, 28669],\n",
            "        [30132, 33106, 26563, 37020, 29485,    22,  7118, 36875,   350,  1116],\n",
            "        [61506, 49334, 61527,  2451,     6, 61506, 49334, 20118,    22, 61528],\n",
            "        [    6,    47, 16961,  3384, 56654,  1162,  5010,  2760,   753,  5441],\n",
            "        [  463,   415, 40750,   753, 10128,   326, 40751,  6805,   866,  5135],\n",
            "        [  385, 24282,    30,   726,  9394, 18463,   505,   200,   553,    15],\n",
            "        [ 1329,  1846,   452,   413,   971, 23129,    58, 16023,   212,  1402]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "0PZnD4sYmQdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "iYpgN1FlFTKR"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, n_features, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_features = n_features\n",
        "        self.hidden = None\n",
        "        #self.embedding_dimension = 256\n",
        "        self.embd = nn.Embedding(self.n_features, self.hidden_dim)\n",
        "        self.basic_rnn = nn.GRU(self.hidden_dim, self.hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X_embd = self.embd(X) # N, F -> N, F, H\n",
        "        rnn_out, self.hidden = self.basic_rnn(X_embd) # N, F, H x N, H, H  ->  N, F, H\n",
        "\n",
        "        return rnn_out, self.hidden # N, F, H"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Encoder"
      ],
      "metadata": {
        "id": "z2OTE4U7nj42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Uncomment to test the code (make sure you are using CPU otherwise this code will going to throw runtime error)\n",
        "\n",
        "#torch.manual_seed(21)\n",
        "# full_seq = torch.full((2, 3), 1)\n",
        "# encoder = Encoder(n_features=3, hidden_dim=5)\n",
        "# hidden_seq, hidden_final = encoder(full_seq) # output is N, L, F\n",
        "# hidden_final.size()"
      ],
      "metadata": {
        "id": "4tvbqkAenlVY"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder"
      ],
      "metadata": {
        "id": "iWsDZeq_o_ZT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "xXs9hsKkFTKT"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.hidden = None\n",
        "        self.embedding = nn.Embedding(output_size, self.hidden_dim)\n",
        "        self.basic_rnn = nn.GRU(self.hidden_dim, self.hidden_dim, batch_first=True)\n",
        "        self.regression = nn.Linear(self.hidden_dim, output_size)\n",
        "\n",
        "    def init_hidden(self, hidden_seq):\n",
        "        # We only need the final hidden state from encoder for each sentence\n",
        "        hidden_final = hidden_seq[:, -1:] # N, F\n",
        "        #self.hidden = hidden_final\n",
        "        self.hidden = hidden_final.permute(1, 0, 2) # 1, N, H   Because output of encoder is sequence first but GRU expects batch first\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.embedding(X) # N, F -> N, F, H\n",
        "        batch_first_output, self.hidden = self.basic_rnn(X, self.hidden) # N, F, H x N, H, H -> N, F, H\n",
        "        out = self.regression(batch_first_output) # N, F, output_size\n",
        "\n",
        "        # N, F, output_size\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fKXfgWcgXPd"
      },
      "source": [
        "## Testing Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "ZfLh-gpxFTKT"
      },
      "outputs": [],
      "source": [
        "### Uncomment to test the code (make sure you are using CPU otherwise this code will going to throw runtime error)\n",
        "\n",
        "# torch.manual_seed(21)\n",
        "# decoder = Decoder(output_size=5, hidden_dim=5)\n",
        "# batch_size = 16\n",
        "\n",
        "# # Initial hidden state will be encoder's final hidden state\n",
        "# decoder.init_hidden(hidden_seq)\n",
        "# # Initial data point is the last element of source sequence\n",
        "# #inputs = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "# inputs = torch.empty(2, 1, dtype=torch.long, device=device).fill_(SOS_token)  # remove me\n",
        "\n",
        "# decoder_outputs = []\n",
        "# target_len = 2\n",
        "# for i in range(target_len):\n",
        "#     print(f'Hidden: {decoder.hidden}')\n",
        "#     decoder_output = decoder(inputs)   # Predicts coordinates\n",
        "#     decoder_outputs.append(decoder_output)\n",
        "#     _, topi = decoder_output.topk(1)\n",
        "#     inputs = topi.squeeze(-1).detach()  # detach from history as input\n",
        "#     print(f'Output: {decoder_output}\\n')\n",
        "# decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "# print(f'combinet_outputs: {decoder_outputs}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF2QNOHQFTKs"
      },
      "source": [
        "# Decoder with attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "I1ibxeceU3OR"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim, input_dim=None, proj_values=False):\n",
        "        super().__init__()\n",
        "        self.d_k = hidden_dim\n",
        "        self.input_dim = hidden_dim if input_dim is None else input_dim\n",
        "        self.proj_values = proj_values\n",
        "        # Affine transformations for Q, K, and V\n",
        "        self.linear_query = nn.Linear(self.input_dim, hidden_dim)\n",
        "        self.linear_key = nn.Linear(self.input_dim, hidden_dim)\n",
        "        self.linear_value = nn.Linear(self.input_dim, hidden_dim)\n",
        "        self.alphas = None\n",
        "\n",
        "    def init_keys(self, keys):\n",
        "        self.keys = keys\n",
        "        self.proj_keys = self.linear_key(self.keys) # N, F, H x N, H, H -> N, F, H\n",
        "        self.values = self.linear_value(self.keys) if self.proj_values else self.keys  # N, F, H x N, H, H -> N, F, H\n",
        "\n",
        "    def score_function(self, query):\n",
        "        proj_query = self.linear_query(query) # N, 1, H x N, H, H -> N, 1, H\n",
        "        # scaled dot product\n",
        "        # N, 1, H x N, H, F -> N, 1, F\n",
        "        dot_products = torch.bmm(proj_query, self.proj_keys.permute(0, 2, 1))\n",
        "        scores =  dot_products / np.sqrt(self.d_k)\n",
        "        return scores\n",
        "\n",
        "    def forward(self, query, mask=None):\n",
        "        # Query is batch-first N, 1, H\n",
        "        # L or F means sequence length\n",
        "        scores = self.score_function(query) # N, 1, F\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        alphas = F.softmax(scores, dim=-1) # N, 1, F\n",
        "        self.alphas = alphas.detach()\n",
        "\n",
        "        # N, 1, F x N, F, H -> N, 1, H\n",
        "        context = torch.bmm(alphas, self.values)\n",
        "        return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4jhEhcL22Ze"
      },
      "source": [
        "### Decoder with rnn and attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "XqGzrKwyb79a"
      },
      "outputs": [],
      "source": [
        "class DecoderAttn(nn.Module):\n",
        "    def __init__(self, output_size, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.hidden = None\n",
        "        self.output_size = output_size\n",
        "        self.embedding = nn.Embedding(output_size, self.hidden_dim)\n",
        "        self.basic_rnn = nn.GRU(self.hidden_dim, self.hidden_dim, batch_first=True)\n",
        "        self.attn = Attention(self.hidden_dim)\n",
        "        self.regression = nn.Linear(2 * self.hidden_dim, self.output_size)\n",
        "\n",
        "    def init_hidden(self, hidden_seq):\n",
        "        # the output of the encoder is N, F, H\n",
        "        # and init_keys expects batch-first as well\n",
        "        self.attn.init_keys(hidden_seq)\n",
        "        hidden_final = hidden_seq[:, -1:]\n",
        "        self.hidden = hidden_final.permute(1, 0, 2)   # F, N, H\n",
        "\n",
        "    def forward(self, X, mask=None):\n",
        "        # X is N, 1\n",
        "        # N is batch size, H is hidden dimensions\n",
        "        X = self.embedding(X) # N, 1 -> N, 1, H\n",
        "        batch_first_output, self.hidden = self.basic_rnn(X, self.hidden) # N, 1, H x N, H, H -> N, 1, H\n",
        "\n",
        "        query = batch_first_output # N, 1, H\n",
        "        # Attention\n",
        "        context = self.attn(query, mask=mask) # N, 1, H\n",
        "        concatenated = torch.cat([context, query], axis=-1) # N, 1, 2*H\n",
        "        out = self.regression(concatenated)  # N, 1, 2*H x N, 2*H, 1 -> N, 1, 1\n",
        "\n",
        "        # N, 1, F\n",
        "        return out.view(-1, 1, self.output_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Test Decoder with RNN and Attention"
      ],
      "metadata": {
        "id": "mTv5QmWdRtDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "6s6X8wPInasL"
      },
      "outputs": [],
      "source": [
        "### Uncomment to test the code (make sure you are using CPU otherwise this code will going to throw runtime error)\n",
        "\n",
        "# torch.manual_seed(21)\n",
        "# decoder = DecoderAttn(output_size=5, hidden_dim=5)\n",
        "\n",
        "# # Initial hidden state will be encoder's final hidden state\n",
        "# decoder.init_hidden(hidden_seq)\n",
        "# # Initial data point is the last element of source sequence\n",
        "# #inputs = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "# inputs = torch.empty(2, 1, dtype=torch.long, device=device).fill_(SOS_token)  # remove me\n",
        "\n",
        "# decoder_outputs = []\n",
        "# target_len = 2\n",
        "# for i in range(target_len):\n",
        "#     print(f'Hidden: {decoder.hidden}')\n",
        "#     decoder_output = decoder(inputs)   # Predicts coordinates\n",
        "#     decoder_outputs.append(decoder_output)\n",
        "#     _, topi = decoder_output.topk(1)\n",
        "#     inputs = topi.squeeze(-1).detach()  # detach from history as input\n",
        "#     print(f'Output: {decoder_output}\\n')\n",
        "# decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "# print(f'combinet_outputs: {decoder_outputs}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8eUVUI1gbCw"
      },
      "source": [
        "# Encoder-Decoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "YrxSffbEvNUl"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, target_len, teacher_forcing_prob=0.5):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.target_len = target_len\n",
        "        self.teacher_forcing_prob = teacher_forcing_prob\n",
        "        self.outputs = None\n",
        "\n",
        "    def init_outputs(self, batch_size):\n",
        "        device = next(self.parameters()).device\n",
        "        # N, L (target), F\n",
        "        self.outputs = torch.zeros(batch_size,\n",
        "                              self.target_len,\n",
        "                              self.encoder.n_features).to(device)\n",
        "\n",
        "    def store_output(self, i, out):\n",
        "        # Stores the output\n",
        "        self.outputs[:, i:i+1, :] = out\n",
        "\n",
        "    def forward(self, X, target_tensor=None):\n",
        "        # X is batch of sentences -> N, F\n",
        "        # splits the data in source and target sequences\n",
        "        # the target seq will be empty in testing mode\n",
        "        # N, L, F\n",
        "\n",
        "        # Encoder expected N, F\n",
        "        hidden_seq, hidden_final = self.encoder(X)\n",
        "        # Output is N, F, hidden_dim\n",
        "        self.decoder.init_hidden(hidden_seq)\n",
        "\n",
        "        # The last input of the encoder is also\n",
        "        # the first input of the decoder\n",
        "        #dec_inputs = source_seq[:, -1:, :]\n",
        "        batch_size = hidden_seq.size(0)\n",
        "\n",
        "        dec_inputs = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_outputs = []\n",
        "        # Generates as many outputs as the target length\n",
        "        for i in range(self.target_len):\n",
        "            # Output of decoder is N, 1, F\n",
        "            decoder_output = self.decoder(dec_inputs)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            prob = self.teacher_forcing_prob\n",
        "\n",
        "            # In evaluation/test the target sequence is\n",
        "            # unknown, so we cannot use teacher forcing\n",
        "            #if not self.training:\n",
        "            #   prob = 0\n",
        "\n",
        "            if torch.rand(1) <= prob and target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "            #_, topi = decoder_output.topk(1)\n",
        "            #dec_inputs = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "QJ_DI8_QG9yX"
      },
      "outputs": [],
      "source": [
        "### Uncomment to test the code (make sure you are using CPU otherwise this code will going to throw runtime error)\n",
        "\n",
        "# hidden_size = 128\n",
        "# batch_size = 32\n",
        "# encoder = Encoder(lang.n_words, hidden_size).to(device)\n",
        "# decoder = Decoder(lang.n_words, hidden_size).to(device)\n",
        "# encdec = EncoderDecoder(encoder, decoder, target_len=5)\n",
        "\n",
        "# outputs = encdec(full_seq)\n",
        "# _, topi = outputs.topk(1)\n",
        "# topi.squeeze(-1).detach()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "tvDRJjMxvqJJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "t3sXkZ6xNOWV"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, model, optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        decoder_outputs = model(input_tensor, target_tensor)\n",
        "\n",
        "        loss = F.cross_entropy(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        # Step 4 - Updates parameters using gradients and the learning rate\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "CU08RsKeNOWY"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "vQM1wNGaNOWc"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, model, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, model, optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "p8bewjTmCs1Q"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "g1VpUdEC9Cev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10dc5b32-b082-48e9-8bfa-416e83930921"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing data...\n",
            "input_ids length: 3579, target_ids length: 3579\n",
            "0m 30s (- 7m 34s) (5 6%) 7.0192\n",
            "1m 0s (- 7m 4s) (10 12%) 4.6284\n",
            "1m 30s (- 6m 34s) (15 18%) 2.9824\n",
            "2m 1s (- 6m 4s) (20 25%) 2.1110\n",
            "2m 33s (- 5m 38s) (25 31%) 1.5964\n",
            "3m 4s (- 5m 6s) (30 37%) 1.2386\n",
            "3m 34s (- 4m 35s) (35 43%) 0.9799\n",
            "4m 4s (- 4m 4s) (40 50%) 0.7878\n",
            "4m 35s (- 3m 33s) (45 56%) 0.6306\n",
            "5m 5s (- 3m 3s) (50 62%) 0.5243\n",
            "5m 35s (- 2m 32s) (55 68%) 0.4384\n",
            "6m 6s (- 2m 2s) (60 75%) 0.3357\n",
            "6m 37s (- 1m 31s) (65 81%) 0.3117\n",
            "7m 8s (- 1m 1s) (70 87%) 0.2562\n",
            "7m 40s (- 0m 30s) (75 93%) 0.1876\n",
            "8m 11s (- 0m 0s) (80 100%) 0.1884\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "# Encoder-Decoder with RNN\n",
        "#encoder = Encoder(lang.n_words, hidden_size).to(device)\n",
        "#decoder = Decoder(lang.n_words, hidden_size).to(device)\n",
        "#model = EncoderDecoder(encoder, decoder, target_len=10)\n",
        "\n",
        "# Encoder-Decoder with Attention and RNN (The best model so far)\n",
        "encoder = Encoder(lang.n_words, hidden_size).to(device)\n",
        "decoder = DecoderAttn(lang.n_words, hidden_size).to(device)\n",
        "model = EncoderDecoder(encoder, decoder, target_len=10)\n",
        "\n",
        "# Encoder-Decoder Self-Attention\n",
        "#encoder = EncoderSelfAttn(n_features=input_lang.n_words, d_model=hidden_size, n_heads=4, ff_units=4).to(device)\n",
        "#decoder = DecoderSelfAttn(n_features=output_lang.n_words, d_model=hidden_size, n_heads=4, ff_units=4).to(device)\n",
        "#model = EncoderDecoderSelfAttention(encoder, decoder, target_len=10)\n",
        "\n",
        "train(train_dataloader, model, 80, print_every=5, plot_every=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "v-aAtvPMkRq6"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, input_tensor, lang):\n",
        "    with torch.no_grad():\n",
        "        #input_tensor = encode(sentence)\n",
        "\n",
        "        decoder_outputs = model(input_tensor)\n",
        "        #print(decoder_outputs)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(lang.index2word[idx.item()])\n",
        "    return decoded_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "qv_tn_KGq8Ph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbd39ad6-f871-4a90-98a8-ff2770862fd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderDecoder(\n",
              "  (encoder): Encoder(\n",
              "    (embd): Embedding(71596, 128)\n",
              "    (basic_rnn): GRU(128, 128, batch_first=True)\n",
              "  )\n",
              "  (decoder): DecoderAttn(\n",
              "    (embedding): Embedding(71596, 128)\n",
              "    (basic_rnn): GRU(128, 128, batch_first=True)\n",
              "    (attn): Attention(\n",
              "      (linear_query): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (linear_key): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (linear_value): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (regression): Linear(in_features=256, out_features=71596, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "model.eval() # Set to evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 10 # number of sentences we want to predict\n",
        "number_of_predictions = 0\n",
        "\n",
        "for input_tensor, target_tensor in train_dataloader:\n",
        "    # Randomly choose an index\n",
        "    index = random.choice(range(len(input_tensor)))\n",
        "\n",
        "    # Choose both the input and target tensors at the selected index\n",
        "    input_tensor = input_tensor[index].view(1, -1)\n",
        "    target_tensor = target_tensor[index].view(1, -1)\n",
        "\n",
        "    #print(\"Input Tensor Size:\", input_tensor.size())\n",
        "    #print(\"Target Tensor Size:\", target_tensor.size())\n",
        "\n",
        "    # Prepare components for printing\n",
        "    input_sentence = decode(input_tensor.view(-1).tolist())\n",
        "    predicted_sentence = ' '.join(evaluate(model, input_tensor, lang))\n",
        "    correct_target = decode(target_tensor.view(-1).tolist())\n",
        "\n",
        "    #print(f\"{decode(input_tensor.view(-1).tolist())} -> {' '.join(evaluate(model, input_tensor, lang))}, CORRECT TARGET: {decode(target_tensor.view(-1).tolist())}\")\n",
        "    #print(f\"Input Sentence: {input_sentence:80}, Predicted Output: {predicted_sentence:20}, Correct Target: {correct_target:20}\")\n",
        "\n",
        "    print(f\"Input Sentence:     {input_sentence}\")\n",
        "    print(f\"Predicted Sentence: {predicted_sentence}\")\n",
        "    print(f\"Correct Target:     {correct_target}\")\n",
        "    print()\n",
        "\n",
        "    number_of_predictions += 1\n",
        "    if number_of_predictions > count:\n",
        "        break"
      ],
      "metadata": {
        "id": "SmE8WHmOnQmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49b13fc4-a947-4db8-82ee-9cbf77f0e923"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence:     Tarsus. A room in Cleon’s house. Enter Pericles, Cleon, Dionyza\n",
            "Predicted Sentence: A room in Cleon’s house. Enter Pericles, Cleon, Dionyza and\n",
            "Correct Target:     A room in Cleon’s house. Enter Pericles, Cleon, Dionyza and\n",
            "\n",
            "Input Sentence:     With reservation of an hundred knights, By you to be\n",
            "Predicted Sentence: reservation of an hundred knights, By you to be sustain’d,\n",
            "Correct Target:     reservation of an hundred knights, By you to be sustain’d,\n",
            "\n",
            "Input Sentence:     my arms before the legs of this sweet lass of\n",
            "Predicted Sentence: arms before the legs this of sweet lass of France._\n",
            "Correct Target:     arms before the legs of this sweet lass of France._\n",
            "\n",
            "Input Sentence:     you should safe my going, Is Fulvia’s death. CLEOPATRA. Though\n",
            "Predicted Sentence: should safe my going, Is Fulvia’s death. CLEOPATRA. Though age\n",
            "Correct Target:     should safe my going, Is Fulvia’s death. CLEOPATRA. Though age\n",
            "\n",
            "Input Sentence:     hath put on nature’s power, Fairing the foul with art’s\n",
            "Predicted Sentence: put on nature’s power, Fairing the foul with art’s false\n",
            "Correct Target:     put on nature’s power, Fairing the foul with art’s false\n",
            "\n",
            "Input Sentence:     ecstacy was ne’er so thrall’d But it reserv’d some quantity\n",
            "Predicted Sentence: was ne’er so thrall’d But it reserv’d some quantity of\n",
            "Correct Target:     was ne’er so thrall’d But it reserv’d some quantity of\n",
            "\n",
            "Input Sentence:     the time; bear welcome in your eye, Your hand, your\n",
            "Predicted Sentence: time; bear in in in eye, Your hand, your tongue:\n",
            "Correct Target:     time; bear welcome in your eye, Your hand, your tongue:\n",
            "\n",
            "Input Sentence:     DAUPHIN. Would I were able to load him with his\n",
            "Predicted Sentence: Would I were able to load him with with desert!\n",
            "Correct Target:     Would I were able to load him with his desert!\n",
            "\n",
            "Input Sentence:     Cell. Scene II. Hall in Capulet’s House. Scene III. Juliet’s\n",
            "Predicted Sentence: Scene II. Hall in Capulet’s House. Scene III. Juliet’s Chamber.\n",
            "Correct Target:     Scene II. Hall in Capulet’s House. Scene III. Juliet’s Chamber.\n",
            "\n",
            "Input Sentence:     know; ’tis but the time And drawing days out, that\n",
            "Predicted Sentence: ’tis but the time time drawing days out, that men\n",
            "Correct Target:     ’tis but the time And drawing days out, that men\n",
            "\n",
            "Input Sentence:     and kill’d. You must not dare, for shame, to talk\n",
            "Predicted Sentence: kill’d. You must not dare, for shame, to talk of\n",
            "Correct Target:     kill’d. You must not dare, for shame, to talk of\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Enter custom text\n",
        "input_text = input(\"Enter a sentence (default: 'For, though before his face I speak the words, Your'): \") or \"For, though before his face I speak the words, Your\"\n",
        "input_tensor = encode(input_text) # \"though before his face I speak the words, Your\"\n",
        "input_tensor = torch.tensor(input_tensor, dtype=torch.long).view(1, -1).to(device)\n",
        "' '.join(evaluate(model, input_tensor, lang))"
      ],
      "metadata": {
        "id": "Cgs0ULAvs3jg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a68c11fb-19ab-4b18-86f0-d6285bbb1ce5"
      },
      "execution_count": 61,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a sentence (default: 'For, though before his face I speak the words, Your'): \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'his his his I I the the Your Your Your'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save and Load the Trained Model"
      ],
      "metadata": {
        "id": "YCH91dEXtq-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/smallGPT.pth'"
      ],
      "metadata": {
        "id": "If9BIhl8utB-"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), PATH)"
      ],
      "metadata": {
        "id": "o-C0sMWjtkwh"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "61XLtZSYtw94"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}