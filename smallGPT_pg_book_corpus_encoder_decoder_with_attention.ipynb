{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQzapzE6mRVWGcGoebXUVT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sukhmancs/TextWizards/blob/main/smallGPT_pg_book_corpus_encoder_decoder_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**_Note:_ MAX_LENGTH must be equal to the target_len**"
      ],
      "metadata": {
        "id": "Xob-BL_2T8Gq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "s8GUcGTDbl4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install chromadb==0.4.10 tiktoken==0.3.3 sqlalchemy==2.0.15\n",
        "!pip install langchain==0.0.249\n",
        "#!pip install --force-reinstall pydantic==1.10.6\n",
        "#!pip install sentence_transformers"
      ],
      "metadata": {
        "id": "BaPotns5Vw9-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import modules and Download data"
      ],
      "metadata": {
        "id": "Q1Ww3lfZjNF2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZlXhowrVhY7"
      },
      "outputs": [],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain, ConversationalRetrievalChain, ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.schema import messages_from_dict, messages_to_dict\n",
        "from langchain.memory.chat_message_histories.in_memory import ChatMessageHistory\n",
        "from langchain.agents import Tool\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import GutenbergLoader\n",
        "\n",
        "loader = GutenbergLoader(\n",
        "    \"https://www.gutenberg.org/cache/epub/100/pg100.txt\"\n",
        ")\n",
        "\n",
        "document = loader.load()\n",
        "\n",
        "extrait = ' '.join(document[0].page_content.split()[:100])\n",
        "display(extrait + \" .......\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "6NqLHt0yV3PQ",
        "outputId": "1e5e5307-303f-40ac-9fb6-cbb4942f7f70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The Project Gutenberg eBook of The Complete Works of William Shakespeare This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this ebook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook. Title: The Complete Works of William Shakespeare .......'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = ' '.join(document[0].page_content.split())"
      ],
      "metadata": {
        "id": "L298xL6FbYgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, random_split, TensorDataset, RandomSampler\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random"
      ],
      "metadata": {
        "id": "unFkoAxNfiUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Data"
      ],
      "metadata": {
        "id": "WaBW4U6xjI7z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBB4zRME3KzL"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Lang:\n",
        "    def __init__(self):\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.n_words = 2  # Count SOS and EOS\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        # To Do: Add normalizeString() function in here to to normalize the sentence (i.e. data)\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    # To Do: Define normalizeString() function in here\n",
        "    def normalizeString(s):\n",
        "        # Start code\n",
        "        pass\n",
        "        # End code\n",
        "\n",
        "    # To Do: Define unicodeToAscii(s) function in here\n",
        "    def unicodeToAscii(s):\n",
        "        # Start code\n",
        "        pass\n",
        "        # End code\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p71SzQiJ3rLN"
      },
      "outputs": [],
      "source": [
        "# Turn a Unicode string to plain ASCII, thanks to\n",
        "# https://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Lowercase, trim, and remove non-letter characters\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-53sCMxTNOWC"
      },
      "outputs": [],
      "source": [
        "MAX_LENGTH = 10\n",
        "\n",
        "eng_prefixes = (\n",
        "    \"i am \", \"i m \",\n",
        "    \"he is\", \"he s \",\n",
        "    \"she is\", \"she s \",\n",
        "    \"you are\", \"you re \",\n",
        "    \"we are\", \"we re \",\n",
        "    \"they are\", \"they re \"\n",
        ")\n",
        "\n",
        "def filterPair(p):\n",
        "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
        "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
        "        p[1].startswith(eng_prefixes)\n",
        "\n",
        "\n",
        "def filterPairs(pairs):\n",
        "    return [pair for pair in pairs if filterPair(pair)]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lang = Lang()\n",
        "lang.addSentence(data)\n",
        "encode = lambda s: [lang.word2index[word] for word in s.split(' ')] # encoder: take a string, output a list of integers\n",
        "decode = lambda l: ' '.join([lang.index2word[i] for i in l]) # decoder: take a list of integers, output a string"
      ],
      "metadata": {
        "id": "psaW9lOlgmO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encode(\"what values are available\"))\n",
        "print(decode(encode(\"what values are available\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YParNcFji98H",
        "outputId": "16e69a97-2dc0-481d-f403-5078249854e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[509, 20726, 52, 71246]\n",
            "what values are available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's now encode the entire text dataset and store it into a torch.Tensor\n",
        "data = torch.tensor(encode(data), dtype=torch.long)\n",
        "print(data.shape, data.dtype)\n",
        "print(data[:1000]) # the 1000 characters we looked at earier will to the GPT look like this"
      ],
      "metadata": {
        "id": "u11Xb_CujxIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "968a53e9-2357-40b7-d25d-1b8529bc379c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([966501]) torch.int64\n",
            "tensor([  2,   3,   4,   5,   6,   2,   7,   8,   6,   9,  10,  11,  12,  13,\n",
            "         14,  15,  16,   6,  17,  18,  19,  15,  20,  21,  22,  23,  24,  25,\n",
            "          6,  15,  26,  27,  28,  29,  22,  30,  31,  28,  32,  33,  34,  35,\n",
            "         36,  37,  38,  39,  40,  41,  42,  39,  43,  15,  44,   6,  15,   3,\n",
            "          4,  45,  46,  30,  47,  12,  41,  48,  27,  49,  50,  51,  52,  53,\n",
            "         54,  19,  15,  20,  55,  51,  56,  57,  58,  59,  15,  60,   6,  15,\n",
            "         61,  62,  51,  52,  54,  63,  64,  47,  65,  66,   2,   7,   8,   6,\n",
            "          9,  10,  67,   9,  10,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
            "         77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  86,\n",
            "         90,  91,  85,  92,  93,  83,   2,   7,   8,   6,   9,  10,  94,   9,\n",
            "         10,  95,  86,  96,  97,  98,  99, 100,  98,  86, 101,  85, 102, 103,\n",
            "        104, 105, 106, 107, 108,  86, 109,  85, 110,  86, 101,  85, 111, 112,\n",
            "         86, 101,  85, 113, 114,  85, 115,  86, 116, 117,  85, 118, 119,  86,\n",
            "        120,  86, 121, 117,  85, 118, 119,  86, 120,  86, 122,  85, 118, 119,\n",
            "         86, 123,  86, 116, 117,  85, 119,  86, 124,  86, 121, 117,  85, 118,\n",
            "        119,  86, 124,  86, 125, 117,  85, 118, 119,  86, 124, 118, 119,  86,\n",
            "        126,  86, 122, 103, 127,  85, 118, 128,  86, 101,  85, 129, 130,  86,\n",
            "        101,  85, 118, 131, 132, 133, 134,  86, 101,  85, 135, 136, 137, 136,\n",
            "         86, 138,  85, 139,  86, 140, 141,  85, 142, 143, 144, 145, 146, 147,\n",
            "        148, 149, 150,  86, 101,  85, 151,  86, 152,  85, 139, 153, 114,  85,\n",
            "        154, 118, 155,  86, 121, 118, 155,  86, 125,  86, 101,  85, 156, 103,\n",
            "        157,  86, 158,  85,  86, 159,  86, 160,  86, 122,  85, 161,  85, 162,\n",
            "         86, 101,  85, 163, 164, 165, 103, 166, 167, 168, 169, 170, 106, 171,\n",
            "         86, 172, 173,  85, 174,  86, 172, 175, 176,  86, 177, 178, 143, 179,\n",
            "        180,  86, 181, 182,  86, 183, 103,  86, 184,  86, 185,  85, 186, 187,\n",
            "        103, 188,  86,  96, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198,\n",
            "        199, 200, 201, 202, 203, 204,  15, 205, 206,  94, 207, 208, 209, 210,\n",
            "        211, 200, 212, 213, 214, 203, 215, 216,  58, 217, 218, 219, 220, 221,\n",
            "        222, 223, 224,  30, 225, 226, 227, 228, 229,  62, 230, 231, 232, 222,\n",
            "        233,  58, 222, 234, 235, 236, 237, 238, 239, 240, 241,  15, 242, 243,\n",
            "        244, 245, 246, 247,  58,  15, 248, 249, 250, 217, 218, 251, 252, 222,\n",
            "        253, 254, 210, 255, 256, 257,  19, 258, 259,  15, 260,  41, 261,  47,\n",
            "        262, 263, 264, 265,  15, 242, 266,  94,  15, 267,  22, 268, 269, 270,\n",
            "        271, 272, 273, 274, 222, 275, 245, 276, 277, 278,  19, 222, 198, 279,\n",
            "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 228, 290, 291,   6,\n",
            "        292, 293, 294, 295, 296, 297,  62, 298, 222, 299, 231, 300, 298,  15,\n",
            "        301,   6, 222, 302, 303, 264, 304, 305, 217, 218, 277, 306, 220, 307,\n",
            "        308, 309, 310,  22, 311, 312, 313, 314, 315, 316, 317, 222, 198, 318,\n",
            "         50, 215, 319, 320, 321, 322, 323,   6, 324, 325, 326, 327, 328,  22,\n",
            "        329, 327, 330, 331, 332, 213, 299,  94, 333, 334,  11, 335,  58, 289,\n",
            "        336, 337, 338, 215, 240, 339, 245, 340, 222, 341, 342, 338, 215, 343,\n",
            "         39, 344, 345, 346,  19, 222, 347,  22, 348,  15, 349, 215, 350, 351,\n",
            "         13,  15, 207, 239, 349, 206, 352, 353, 354, 243, 355, 356, 241, 215,\n",
            "         53, 357, 238, 358, 359,  15, 260, 360, 361, 362, 363,  62,  13, 364,\n",
            "        284, 322, 365, 366, 367, 368,  15, 369,   6, 222, 370, 371, 372,  13,\n",
            "        373, 284, 374,  56, 289,  15, 375, 376, 213, 377,  58, 378, 379, 238,\n",
            "        240, 222, 380, 347,  22, 364,  19, 381, 382, 383,  15, 384, 385,   6,\n",
            "        386, 387, 388, 215, 389, 390,   6, 217, 391, 392, 393, 394,   6, 395,\n",
            "         47, 222, 396, 397, 203, 356, 215, 398, 399,  53,  58, 263, 400, 401,\n",
            "         22, 217, 402, 403,  30, 268, 404, 405, 406, 407, 358, 215, 408, 409,\n",
            "        410, 222, 198, 411, 412, 413, 414, 415, 416, 417, 418, 245, 296, 419,\n",
            "        364, 420,  58, 421,  52, 422, 295, 423, 424, 407, 358, 215, 425,   2,\n",
            "        426, 427, 428, 381,  58, 429, 430, 431, 407, 358, 215,  16, 388, 432,\n",
            "        228, 326,   6, 433, 434, 435,  53, 436, 363, 437, 438,  30, 410, 439,\n",
            "        238,   6, 410, 222, 234, 235, 358, 440, 295, 441, 338, 442, 443, 381,\n",
            "         58, 289, 444, 445, 446, 447, 435, 215, 448, 280, 449, 299, 450, 289,\n",
            "        451,  30, 452, 453, 454, 455, 456, 457,  58, 458, 459, 460, 461, 239,\n",
            "         30, 462, 463, 464, 465,   2, 384, 466,  62, 467, 468, 417, 469, 288,\n",
            "        470,  15, 471,  58,  15, 472, 473, 245, 239, 474, 475, 476, 417, 477,\n",
            "        363, 478, 207, 479, 480, 286, 264, 481, 482,  22, 483, 484, 485, 486,\n",
            "        487,  30, 488,  22, 302, 489, 490, 444, 491, 492,  22, 493, 467, 494,\n",
            "        295, 335,  53, 495, 496, 497, 143, 498, 499, 500,  19, 501,   6, 502,\n",
            "        503, 504,  30, 299, 335, 505, 506,  39, 507,  28, 508, 509,  39, 510,\n",
            "        203, 511, 512, 513, 514,  30, 482, 515, 516, 416, 517, 518, 517, 519,\n",
            "        520, 455, 521, 522, 295, 523,  53, 524, 525, 526, 527, 528, 381, 222,\n",
            "        480, 529, 215, 289, 530, 531, 234, 361, 532, 301, 215, 361, 533, 534,\n",
            "        198, 301, 529,  39, 289, 535, 196,  16,  13,  53, 536, 537, 453, 538,\n",
            "        421, 239, 539,  15, 540, 541, 542,  14, 410,  58, 543, 544, 452, 371,\n",
            "        545, 546, 547, 289,  39, 545,  14, 548, 549, 546, 410, 335, 547, 550,\n",
            "        215, 551,  50, 545,   6, 217, 545, 546, 552, 553, 295, 509, 554, 555,\n",
            "        556, 356, 215, 557, 558, 559, 381, 560,  19, 379, 561,  53, 562,  14,\n",
            "        215, 240, 314, 236, 563, 264])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's now split up the data into train and validation sets\n",
        "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "8vD9wPC7kubp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 8\n",
        "x = train_data[:block_size]\n",
        "y = train_data[1:block_size+1]\n",
        "for t in range(block_size):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"when input is {context} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEfMDDsTkftq",
        "outputId": "120f91ff-1b8d-4659-ae95-746814ca0fef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is tensor([2]) the target: 3\n",
            "when input is tensor([2, 3]) the target: 4\n",
            "when input is tensor([2, 3, 4]) the target: 5\n",
            "when input is tensor([2, 3, 4, 5]) the target: 6\n",
            "when input is tensor([2, 3, 4, 5, 6]) the target: 2\n",
            "when input is tensor([2, 3, 4, 5, 6, 2]) the target: 7\n",
            "when input is tensor([2, 3, 4, 5, 6, 2, 7]) the target: 8\n",
            "when input is tensor([2, 3, 4, 5, 6, 2, 7, 8]) the target: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRtnxmuqz2rq"
      },
      "outputs": [],
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "MAX_LENGTH = 10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lang.n_words * 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2h1AwLPIb7i2",
        "outputId": "899e9ff2-612f-40f1-8e76-83854dd50cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3579.8"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZeORww3z2rr"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1337)\n",
        "batch_size = 4 # how many independent sequences will we process in parallel?\n",
        "block_size = 8 # what is the maximum context length for predictions?\n",
        "n_words = lang.n_words\n",
        "\n",
        "def get_batch(split, batch_size):\n",
        "    # generate a small batch of data of inputs x and targets y\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - MAX_LENGTH, (int(n_words * 0.05),))  # How many sentences i need out of ~71k\n",
        "    x = torch.stack([data[i:i+MAX_LENGTH] for i in ix])\n",
        "    y = torch.stack([data[i+1:i+MAX_LENGTH+1] for i in ix])\n",
        "    return x, y\n",
        "\n",
        "def get_dataloader(batch_size, split='train'):\n",
        "    print(\"Parsing data...\")\n",
        "    input_ids, target_ids = get_batch(split, batch_size)\n",
        "    print(f\"input_ids length: {len(input_ids)}, target_ids length: {len(target_ids)}\")\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return train_dataloader\n",
        "\n",
        "xb, yb = get_batch('train', batch_size)\n",
        "print('inputs:')\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print('targets:')\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "print('----')\n",
        "\n",
        "for b in range(batch_size): # batch dimension\n",
        "    for t in range(block_size): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"when input is {context.tolist()} the target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2Wsl0v3k5Mh",
        "outputId": "3408693e-61e7-4cfb-8770-23bff60f2aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs:\n",
            "torch.Size([3579, 10])\n",
            "tensor([[ 2094,   245,   273,  ...,    58,   228, 41029],\n",
            "        [11784,    30, 15195,  ...,  3258,    58,   908],\n",
            "        [ 5178,    15, 44665,  ...,   289,   284, 12862],\n",
            "        ...,\n",
            "        [ 1872, 35235,   118,  ..., 28416,  7387,   765],\n",
            "        [61548,   372,  1081,  ...,  3317, 18563,    94],\n",
            "        [  273,  1062,   933,  ...,    58,    15,  2397]])\n",
            "targets:\n",
            "torch.Size([3579, 10])\n",
            "tensor([[  245,   273,   239,  ...,   228, 41029,  1163],\n",
            "        [   30, 15195, 53804,  ...,    58,   908,   909],\n",
            "        [   15, 44665, 44359,  ...,   284, 12862, 44640],\n",
            "        ...,\n",
            "        [35235,   118, 30761,  ...,  7387,   765,   571],\n",
            "        [  372,  1081,   298,  ..., 18563,    94,    22],\n",
            "        [ 1062,   933,  4854,  ...,    15,  2397,     6]])\n",
            "----\n",
            "when input is [2094] the target: 245\n",
            "when input is [2094, 245] the target: 273\n",
            "when input is [2094, 245, 273] the target: 239\n",
            "when input is [2094, 245, 273, 239] the target: 1301\n",
            "when input is [2094, 245, 273, 239, 1301] the target: 38\n",
            "when input is [2094, 245, 273, 239, 1301, 38] the target: 2486\n",
            "when input is [2094, 245, 273, 239, 1301, 38, 2486] the target: 58\n",
            "when input is [2094, 245, 273, 239, 1301, 38, 2486, 58] the target: 228\n",
            "when input is [11784] the target: 30\n",
            "when input is [11784, 30] the target: 15195\n",
            "when input is [11784, 30, 15195] the target: 53804\n",
            "when input is [11784, 30, 15195, 53804] the target: 34\n",
            "when input is [11784, 30, 15195, 53804, 34] the target: 57\n",
            "when input is [11784, 30, 15195, 53804, 34, 57] the target: 960\n",
            "when input is [11784, 30, 15195, 53804, 34, 57, 960] the target: 3258\n",
            "when input is [11784, 30, 15195, 53804, 34, 57, 960, 3258] the target: 58\n",
            "when input is [5178] the target: 15\n",
            "when input is [5178, 15] the target: 44665\n",
            "when input is [5178, 15, 44665] the target: 44359\n",
            "when input is [5178, 15, 44665, 44359] the target: 34\n",
            "when input is [5178, 15, 44665, 44359, 34] the target: 450\n",
            "when input is [5178, 15, 44665, 44359, 34, 450] the target: 53\n",
            "when input is [5178, 15, 44665, 44359, 34, 450, 53] the target: 289\n",
            "when input is [5178, 15, 44665, 44359, 34, 450, 53, 289] the target: 284\n",
            "when input is [19] the target: 386\n",
            "when input is [19, 386] the target: 12648\n",
            "when input is [19, 386, 12648] the target: 767\n",
            "when input is [19, 386, 12648, 767] the target: 4851\n",
            "when input is [19, 386, 12648, 767, 4851] the target: 204\n",
            "when input is [19, 386, 12648, 767, 4851, 204] the target: 13\n",
            "when input is [19, 386, 12648, 767, 4851, 204, 13] the target: 15\n",
            "when input is [19, 386, 12648, 767, 4851, 204, 13, 15] the target: 251\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = get_dataloader(batch_size=32, split='train')\n",
        "\n",
        "for data in train_dataloader:\n",
        "    inputs, targets = data\n",
        "    print(inputs)\n",
        "    break"
      ],
      "metadata": {
        "id": "blzNNrPqzqCE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34c05b5-235e-4b3a-a117-8f5eda72db9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing data...\n",
            "input_ids length: 3579, target_ids length: 3579\n",
            "tensor([[ 5161,   456,   260,  4809, 26845,  4467,   754, 10492,   484,    63],\n",
            "        [27855,    22, 57200,   116, 36115,   313,   435,   215,  4777,  5813],\n",
            "        [ 2588,   528,  4292,   239,   327,  1384, 26233, 10023,   289,    15],\n",
            "        [  327, 14113,    22,  3020, 62922, 45744,   203,  2486,   765,   234],\n",
            "        [49849,    22,    53,    58,  1306,   228, 49848,  1841,   867, 49850],\n",
            "        [ 2571, 18064, 17498,  5104,   373,    13, 18065,   754,  3064,    15],\n",
            "        [ 1902,   196,  7264,     6, 38577,    19, 12252,  1660,  1306,   213],\n",
            "        [  213,  8787,   335, 16593,    94,   222, 16821,   245,  3070,  3834],\n",
            "        [21737,   670, 24916,  6521,  4949, 39759, 15980,    51,  1343,  1898],\n",
            "        [11766,  4550, 23012,   695,   228,  5176,    58,    15,  1274,   363],\n",
            "        [  765, 11880,   754,   201,  7201,   228, 25015,   507,  5714,   228],\n",
            "        [15210, 51565,  1341,   517,   482,  7499,   720,  1467,    13,   241],\n",
            "        [  739,   284,  1116,   204,   754,  3063, 59507,  5416,   754,  6286],\n",
            "        [  215,  1306,   813,   327,  7987, 20242,  1589,   239,  1307,    58],\n",
            "        [ 2287,  5091, 53956, 53746,   245,  1317,   432,  3853,   239,    15],\n",
            "        [   43,   213,  4499,   373,  9293,    53,  5161,  5813,  3772,  6555],\n",
            "        [  193,    14,  1803,  5650,   286,   475,   609,  1163,  1384,     6],\n",
            "        [ 4889,     2,  2518,   143, 26100,    63,    15, 23030,  7530,    30],\n",
            "        [  245,    24,     6,   727, 48741, 16359,   196,  6635,    53,  1395],\n",
            "        [   56,   754,  4142,   534,   566,   239,    52,   222, 59134,  5104],\n",
            "        [    6,   386,  3393,  4854,  8856,  6554,   386, 22408,    22,  1534],\n",
            "        [  245,   441,   417,   222,  5832, 27837, 26132,  5592,   327,  5015],\n",
            "        [  143, 18102, 30621, 30622,  2623,     6,  8124, 30623,    15, 30624],\n",
            "        [ 7717,    22,   523,   867,  2044,    22,   341,  7068,  3667,  7120],\n",
            "        [37059,    51,   871,  1343,   441,  3783,    39,    13,    58,   289],\n",
            "        [  860,  3852,  3520,   445,  1982, 14120, 28668,  6806,    15, 28669],\n",
            "        [30132, 33106, 26563, 37020, 29485,    22,  7119, 36875,   351,  1117],\n",
            "        [61506, 49334, 61527,  2452,     6, 61506, 49334, 20118,    22, 61528],\n",
            "        [    6,    47, 16961,  3385, 56654,  1163,  5011,  2761,   754,  5442],\n",
            "        [  464,   416, 40750,   754, 10129,   327, 40751,  6806,   867,  5136],\n",
            "        [  386, 24282,    30,   727,  9395, 18463,   506,   201,   554,    15],\n",
            "        [ 1330,  1847,   453,   414,   972, 23129,    58, 16023,   213,  1403]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder"
      ],
      "metadata": {
        "id": "0PZnD4sYmQdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYpgN1FlFTKR"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, n_features, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_features = n_features\n",
        "        self.hidden = None\n",
        "        #self.embedding_dimension = 256\n",
        "        self.embd = nn.Embedding(self.n_features, self.hidden_dim)\n",
        "        self.basic_rnn = nn.GRU(self.hidden_dim, self.hidden_dim, batch_first=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        X_embd = self.embd(X) # N, F -> N, F, H\n",
        "        rnn_out, self.hidden = self.basic_rnn(X_embd) # N, F, H x N, H, H  ->  N, F, H\n",
        "\n",
        "        return rnn_out, self.hidden # N, F, H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6Npk2H3Zu6D"
      },
      "outputs": [],
      "source": [
        "embd = nn.Embedding(5, 5)\n",
        "rnn = nn.GRU(5, 5, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1miZ7VQPZgQl",
        "outputId": "0b4d22b6-6c32-4e66-a1d5-bda419ccbbf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.2507, -0.2187, -0.4002,  0.4740, -0.5513],\n",
              "         [-0.2507, -0.2187, -0.4002,  0.4740, -0.5513]]],\n",
              "       grad_fn=<StackBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "full_seq = torch.full((2, 3), 1)\n",
        "rnn_out, final_hidden = rnn(embd(full_seq))\n",
        "final_hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Encoder"
      ],
      "metadata": {
        "id": "z2OTE4U7nj42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xb.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t89FK1ern9O8",
        "outputId": "c744ee55-e965-43a1-dd28-44285bdb7265"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3579, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.manual_seed(21)\n",
        "encoder = Encoder(n_features=3, hidden_dim=5)\n",
        "hidden_seq, hidden_final = encoder(full_seq) # output is N, L, F\n",
        "hidden_final.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tvbqkAenlVY",
        "outputId": "1b8f9da5-39de-4bbb-dfee-935090d8085f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Decoder"
      ],
      "metadata": {
        "id": "iWsDZeq_o_ZT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXs9hsKkFTKT"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.hidden = None\n",
        "        self.embedding = nn.Embedding(output_size, self.hidden_dim)\n",
        "        self.basic_rnn = nn.GRU(self.hidden_dim, self.hidden_dim, batch_first=True)\n",
        "        self.regression = nn.Linear(self.hidden_dim, output_size)\n",
        "\n",
        "    def init_hidden(self, hidden_seq):\n",
        "        # We only need the final hidden state from encoder for each sentence\n",
        "        hidden_final = hidden_seq[:, -1:] # N, F\n",
        "        #self.hidden = hidden_final\n",
        "        self.hidden = hidden_final.permute(1, 0, 2) # 1, N, H   Because output of encoder is sequence first but GRU expects batch first\n",
        "\n",
        "    def forward(self, X):\n",
        "        X = self.embedding(X) # N, F -> N, F, H\n",
        "        batch_first_output, self.hidden = self.basic_rnn(X, self.hidden) # N, F, H x N, H, H -> N, F, H\n",
        "        out = self.regression(batch_first_output) # N, F, output_size\n",
        "\n",
        "        # N, F, output_size\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_seq[:,-1:].size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fBvTwsxu_AV",
        "outputId": "5af48039-bab2-43cb-da85-b28345b1ee61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTSe6c4Moz9i",
        "outputId": "9681e991-0d04-4fd7-dbfb-87ec0296d67d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[True, True, True, True, True],\n",
              "         [True, True, True, True, True]],\n",
              "\n",
              "        [[True, True, True, True, True],\n",
              "         [True, True, True, True, True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "hidden_seq[:,-1:] == hidden_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fKXfgWcgXPd"
      },
      "source": [
        "## Testing Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfLh-gpxFTKT",
        "outputId": "07c5df95-f7f2-42d1-a9a3-90eee41d1007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden: tensor([[[ 0.5551, -0.0523, -0.8522,  0.5615,  0.6711],\n",
            "         [ 0.5551, -0.0523, -0.8522,  0.5615,  0.6711]]],\n",
            "       grad_fn=<PermuteBackward0>)\n",
            "Output: tensor([[[ 0.3599, -0.0062,  0.1509,  0.1080, -0.0912]],\n",
            "\n",
            "        [[ 0.3599, -0.0062,  0.1509,  0.1080, -0.0912]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "\n",
            "Hidden: tensor([[[ 0.6340, -0.0150, -0.7392,  0.0754,  0.3489],\n",
            "         [ 0.6340, -0.0150, -0.7392,  0.0754,  0.3489]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "Output: tensor([[[ 0.4303,  0.0493,  0.1861,  0.1481, -0.1258]],\n",
            "\n",
            "        [[ 0.4303,  0.0493,  0.1861,  0.1481, -0.1258]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "\n",
            "combinet_outputs: tensor([[[ 0.3599, -0.0062,  0.1509,  0.1080, -0.0912],\n",
            "         [ 0.4303,  0.0493,  0.1861,  0.1481, -0.1258]],\n",
            "\n",
            "        [[ 0.3599, -0.0062,  0.1509,  0.1080, -0.0912],\n",
            "         [ 0.4303,  0.0493,  0.1861,  0.1481, -0.1258]]],\n",
            "       grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(21)\n",
        "decoder = Decoder(output_size=5, hidden_dim=5)\n",
        "batch_size = 16\n",
        "\n",
        "# Initial hidden state will be encoder's final hidden state\n",
        "decoder.init_hidden(hidden_seq)\n",
        "# Initial data point is the last element of source sequence\n",
        "#inputs = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "inputs = torch.empty(2, 1, dtype=torch.long, device=device).fill_(SOS_token)  # remove me\n",
        "\n",
        "decoder_outputs = []\n",
        "target_len = 2\n",
        "for i in range(target_len):\n",
        "    print(f'Hidden: {decoder.hidden}')\n",
        "    decoder_output = decoder(inputs)   # Predicts coordinates\n",
        "    decoder_outputs.append(decoder_output)\n",
        "    _, topi = decoder_output.topk(1)\n",
        "    inputs = topi.squeeze(-1).detach()  # detach from history as input\n",
        "    print(f'Output: {decoder_output}\\n')\n",
        "decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "print(f'combinet_outputs: {decoder_outputs}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gF2QNOHQFTKs"
      },
      "source": [
        "# Decoder with attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1ibxeceU3OR"
      },
      "outputs": [],
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, hidden_dim, input_dim=None, proj_values=False):\n",
        "        super().__init__()\n",
        "        self.d_k = hidden_dim\n",
        "        self.input_dim = hidden_dim if input_dim is None else input_dim\n",
        "        self.proj_values = proj_values\n",
        "        # Affine transformations for Q, K, and V\n",
        "        self.linear_query = nn.Linear(self.input_dim, hidden_dim)\n",
        "        self.linear_key = nn.Linear(self.input_dim, hidden_dim)\n",
        "        self.linear_value = nn.Linear(self.input_dim, hidden_dim)\n",
        "        self.alphas = None\n",
        "\n",
        "    def init_keys(self, keys):\n",
        "        self.keys = keys\n",
        "        self.proj_keys = self.linear_key(self.keys) # N, F, H x N, H, H -> N, F, H\n",
        "        self.values = self.linear_value(self.keys) if self.proj_values else self.keys  # N, F, H x N, H, H -> N, F, H\n",
        "\n",
        "    def score_function(self, query):\n",
        "        proj_query = self.linear_query(query) # N, 1, H x N, H, H -> N, 1, H\n",
        "        # scaled dot product\n",
        "        # N, 1, H x N, H, F -> N, 1, F\n",
        "        dot_products = torch.bmm(proj_query, self.proj_keys.permute(0, 2, 1))\n",
        "        scores =  dot_products / np.sqrt(self.d_k)\n",
        "        return scores\n",
        "\n",
        "    def forward(self, query, mask=None):\n",
        "        # Query is batch-first N, 1, H\n",
        "        # L or F means sequence length\n",
        "        scores = self.score_function(query) # N, 1, F\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e9)\n",
        "        alphas = F.softmax(scores, dim=-1) # N, 1, F\n",
        "        self.alphas = alphas.detach()\n",
        "\n",
        "        # N, 1, F x N, F, H -> N, 1, H\n",
        "        context = torch.bmm(alphas, self.values)\n",
        "        return context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4jhEhcL22Ze"
      },
      "source": [
        "### Decoder with rnn and attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqGzrKwyb79a"
      },
      "outputs": [],
      "source": [
        "class DecoderAttn(nn.Module):\n",
        "    def __init__(self, output_size, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.hidden = None\n",
        "        self.output_size = output_size\n",
        "        self.embedding = nn.Embedding(output_size, self.hidden_dim)\n",
        "        self.basic_rnn = nn.GRU(self.hidden_dim, self.hidden_dim, batch_first=True)\n",
        "        self.attn = Attention(self.hidden_dim)\n",
        "        self.regression = nn.Linear(2 * self.hidden_dim, self.output_size)\n",
        "\n",
        "    def init_hidden(self, hidden_seq):\n",
        "        # the output of the encoder is N, F, H\n",
        "        # and init_keys expects batch-first as well\n",
        "        self.attn.init_keys(hidden_seq)\n",
        "        hidden_final = hidden_seq[:, -1:]\n",
        "        self.hidden = hidden_final.permute(1, 0, 2)   # F, N, H\n",
        "\n",
        "    def forward(self, X, mask=None):\n",
        "        # X is N, 1\n",
        "        # N is batch size, H is hidden dimensions\n",
        "        X = self.embedding(X) # N, 1 -> N, 1, H\n",
        "        batch_first_output, self.hidden = self.basic_rnn(X, self.hidden) # N, 1, H x N, H, H -> N, 1, H\n",
        "\n",
        "        query = batch_first_output # N, 1, H\n",
        "        # Attention\n",
        "        context = self.attn(query, mask=mask) # N, 1, H\n",
        "        concatenated = torch.cat([context, query], axis=-1) # N, 1, 2*H\n",
        "        out = self.regression(concatenated)  # N, 1, 2*H x N, 2*H, 1 -> N, 1, 1\n",
        "\n",
        "        # N, 1, F\n",
        "        return out.view(-1, 1, self.output_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzV9yuD0r6SF"
      },
      "outputs": [],
      "source": [
        "inputs = torch.empty(2, 1, dtype=torch.long, device=device).fill_(SOS_token)  # remove me"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i1Ed221ruvx",
        "outputId": "0cba3419-52e9-4bf5-daff-46373712a78c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "embedding = nn.Embedding(1, 5)\n",
        "embedding(inputs).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6s6X8wPInasL",
        "outputId": "70ae3b7d-9393-46df-9206-63df617ed815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden: tensor([[[ 0.5551, -0.0523, -0.8522,  0.5615,  0.6711],\n",
            "         [ 0.5551, -0.0523, -0.8522,  0.5615,  0.6711]]],\n",
            "       grad_fn=<PermuteBackward0>)\n",
            "Output: tensor([[[-0.6335,  0.0301, -0.3273,  0.0112, -0.2205]],\n",
            "\n",
            "        [[-0.6335,  0.0301, -0.3273,  0.0112, -0.2205]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "\n",
            "Hidden: tensor([[[ 0.6340, -0.0150, -0.7392,  0.0754,  0.3489],\n",
            "         [ 0.6340, -0.0150, -0.7392,  0.0754,  0.3489]]],\n",
            "       grad_fn=<StackBackward0>)\n",
            "Output: tensor([[[-0.4340, -0.1471, -0.4911, -0.1622, -0.1701]],\n",
            "\n",
            "        [[-0.4340, -0.1471, -0.4911, -0.1622, -0.1701]]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "\n",
            "combinet_outputs: tensor([[[-0.6335,  0.0301, -0.3273,  0.0112, -0.2205],\n",
            "         [-0.4340, -0.1471, -0.4911, -0.1622, -0.1701]],\n",
            "\n",
            "        [[-0.6335,  0.0301, -0.3273,  0.0112, -0.2205],\n",
            "         [-0.4340, -0.1471, -0.4911, -0.1622, -0.1701]]],\n",
            "       grad_fn=<CatBackward0>)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(21)\n",
        "decoder = DecoderAttn(output_size=5, hidden_dim=5)\n",
        "\n",
        "# Initial hidden state will be encoder's final hidden state\n",
        "decoder.init_hidden(hidden_seq)\n",
        "# Initial data point is the last element of source sequence\n",
        "#inputs = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "inputs = torch.empty(2, 1, dtype=torch.long, device=device).fill_(SOS_token)  # remove me\n",
        "\n",
        "decoder_outputs = []\n",
        "target_len = 2\n",
        "for i in range(target_len):\n",
        "    print(f'Hidden: {decoder.hidden}')\n",
        "    decoder_output = decoder(inputs)   # Predicts coordinates\n",
        "    decoder_outputs.append(decoder_output)\n",
        "    _, topi = decoder_output.topk(1)\n",
        "    inputs = topi.squeeze(-1).detach()  # detach from history as input\n",
        "    print(f'Output: {decoder_output}\\n')\n",
        "decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "print(f'combinet_outputs: {decoder_outputs}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8eUVUI1gbCw"
      },
      "source": [
        "# Encoder-Decoder Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrxSffbEvNUl"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, encoder, decoder, target_len, teacher_forcing_prob=0.5):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.target_len = target_len\n",
        "        self.teacher_forcing_prob = teacher_forcing_prob\n",
        "        self.outputs = None\n",
        "\n",
        "    def init_outputs(self, batch_size):\n",
        "        device = next(self.parameters()).device\n",
        "        # N, L (target), F\n",
        "        self.outputs = torch.zeros(batch_size,\n",
        "                              self.target_len,\n",
        "                              self.encoder.n_features).to(device)\n",
        "\n",
        "    def store_output(self, i, out):\n",
        "        # Stores the output\n",
        "        self.outputs[:, i:i+1, :] = out\n",
        "\n",
        "    def forward(self, X, target_tensor=None):\n",
        "        # X is batch of sentences -> N, F\n",
        "        # splits the data in source and target sequences\n",
        "        # the target seq will be empty in testing mode\n",
        "        # N, L, F\n",
        "\n",
        "        # Encoder expected N, F\n",
        "        hidden_seq, hidden_final = self.encoder(X)\n",
        "        # Output is N, F, hidden_dim\n",
        "        self.decoder.init_hidden(hidden_seq)\n",
        "\n",
        "        # The last input of the encoder is also\n",
        "        # the first input of the decoder\n",
        "        #dec_inputs = source_seq[:, -1:, :]\n",
        "        batch_size = hidden_seq.size(0)\n",
        "\n",
        "        dec_inputs = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        decoder_outputs = []\n",
        "        # Generates as many outputs as the target length\n",
        "        for i in range(self.target_len):\n",
        "            # Output of decoder is N, 1, F\n",
        "            decoder_output = self.decoder(dec_inputs)\n",
        "            decoder_outputs.append(decoder_output)\n",
        "\n",
        "            prob = self.teacher_forcing_prob\n",
        "\n",
        "            # In evaluation/test the target sequence is\n",
        "            # unknown, so we cannot use teacher forcing\n",
        "            #if not self.training:\n",
        "            #   prob = 0\n",
        "\n",
        "            if torch.rand(1) <= prob and target_tensor is not None:\n",
        "                # Teacher forcing: Feed the target as the next input\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                # Without teacher forcing: use its own predictions as the next input\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n",
        "            #_, topi = decoder_output.topk(1)\n",
        "            #dec_inputs = topi.squeeze(-1).detach()  # detach from history as input\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        return decoder_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ_DI8_QG9yX"
      },
      "outputs": [],
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "encoder = Encoder(lang.n_words, hidden_size).to(device)\n",
        "decoder = Decoder(lang.n_words, hidden_size).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6fv9bBPKz4B"
      },
      "outputs": [],
      "source": [
        "encdec = EncoderDecoder(encoder, decoder, target_len=5)\n",
        "outputs = encdec(full_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hzf9lgD8vcVH",
        "outputId": "538cd5db-3e8f-44ac-a45b-51b3f88a9c5b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[63203, 63203, 42212, 42212, 42212],\n",
              "        [63203, 63203, 42212, 42212, 42212]])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "_, topi = outputs.topk(1)\n",
        "topi.squeeze(-1).detach()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "tvDRJjMxvqJJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3sXkZ6xNOWV"
      },
      "outputs": [],
      "source": [
        "def train_epoch(dataloader, model, optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        decoder_outputs = model(input_tensor, target_tensor)\n",
        "\n",
        "        loss = F.cross_entropy(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        # Step 4 - Updates parameters using gradients and the learning rate\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CU08RsKeNOWY"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQM1wNGaNOWc"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, model, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, model, optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8bewjTmCs1Q"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    # this locator puts ticks at regular intervals\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1VpUdEC9Cev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73dc53ae-a6a0-4a76-b4a1-622b8bafb41c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing data...\n",
            "input_ids length: 3579, target_ids length: 3579\n",
            "29m 32s (- 206m 46s) (5 12%) 7.0049\n",
            "58m 40s (- 176m 2s) (10 25%) 4.6795\n",
            "87m 46s (- 146m 17s) (15 37%) 3.1153\n",
            "116m 55s (- 116m 55s) (20 50%) 2.2926\n",
            "146m 6s (- 87m 39s) (25 62%) 1.7924\n",
            "175m 16s (- 58m 25s) (30 75%) 1.4293\n",
            "204m 24s (- 29m 12s) (35 87%) 1.1644\n",
            "233m 30s (- 0m 0s) (40 100%) 0.9509\n"
          ]
        }
      ],
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "# Encoder-Decoder with RNN\n",
        "#encoder = Encoder(lang.n_words, hidden_size).to(device)\n",
        "#decoder = Decoder(lang.n_words, hidden_size).to(device)\n",
        "#model = EncoderDecoder(encoder, decoder, target_len=10)\n",
        "\n",
        "# Encoder-Decoder with Attention and RNN\n",
        "encoder = Encoder(lang.n_words, hidden_size).to(device)\n",
        "decoder = DecoderAttn(lang.n_words, hidden_size).to(device)\n",
        "model = EncoderDecoder(encoder, decoder, target_len=10)\n",
        "\n",
        "# Encoder-Decoder Self-Attention\n",
        "#encoder = EncoderSelfAttn(n_features=input_lang.n_words, d_model=hidden_size, n_heads=4, ff_units=4).to(device)\n",
        "#decoder = DecoderSelfAttn(n_features=output_lang.n_words, d_model=hidden_size, n_heads=4, ff_units=4).to(device)\n",
        "#model = EncoderDecoderSelfAttention(encoder, decoder, target_len=10)\n",
        "\n",
        "train(train_dataloader, model, 40, print_every=5, plot_every=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-aAtvPMkRq6"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, input_tensor, lang):\n",
        "    with torch.no_grad():\n",
        "        #input_tensor = encode(sentence)\n",
        "\n",
        "        decoder_outputs = model(input_tensor)\n",
        "        #print(decoder_outputs)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(lang.index2word[idx.item()])\n",
        "    return decoded_words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qv_tn_KGq8Ph",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b92bfb12-03fc-426f-ce20-46287954f186"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EncoderDecoder(\n",
              "  (encoder): Encoder(\n",
              "    (embd): Embedding(71596, 128)\n",
              "    (basic_rnn): GRU(128, 128, batch_first=True)\n",
              "  )\n",
              "  (decoder): DecoderAttn(\n",
              "    (embedding): Embedding(71596, 128)\n",
              "    (basic_rnn): GRU(128, 128, batch_first=True)\n",
              "    (attn): Attention(\n",
              "      (linear_query): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (linear_key): Linear(in_features=128, out_features=128, bias=True)\n",
              "      (linear_value): Linear(in_features=128, out_features=128, bias=True)\n",
              "    )\n",
              "    (regression): Linear(in_features=256, out_features=71596, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "model.eval() # Set to evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_tensor, target_tensor in train_dataloader:\n",
        "    # Randomly choose an index\n",
        "    index = random.choice(range(len(input_tensor)))\n",
        "\n",
        "    # Choose both the input and target tensors at the selected index\n",
        "    input_tensor = input_tensor[index].view(1, -1)\n",
        "    target_tensor = target_tensor[index].view(1, -1)\n",
        "\n",
        "    print(\"Input Tensor Size:\", input_tensor.size())\n",
        "    print(\"Target Tensor Size:\", target_tensor.size())\n",
        "\n",
        "    #print(decode(input_tensor.tolist()))\n",
        "    print(f\"{decode(input_tensor.view(-1).tolist())} -> {' '.join(evaluate(model, input_tensor, lang))}, CORRECT TARGET: {decode(target_tensor.view(-1).tolist())}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmE8WHmOnQmz",
        "outputId": "62f243a5-dcbf-4bb6-84d8-47ed8127127e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Tensor Size: torch.Size([1, 10])\n",
            "Target Tensor Size: torch.Size([1, 10])\n",
            "For, though before his face I speak the words, Your -> though before I face I speak the words, Your Your, CORRECT TARGET: though before his face I speak the words, Your brother\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Enter custom text\n",
        "input_text = input(\"Enter a sentence (default: 'though before his face I speak the words, Your'): \") or \"For, though before his face I speak the words, Your\"\n",
        "input_tensor = encode(input_text) # \"though before his face I speak the words, Your\"\n",
        "input_tensor = torch.tensor(input_tensor, dtype=torch.long).view(1, -1)\n",
        "' '.join(evaluate(model, input_tensor, lang))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "cellView": "form",
        "id": "Cgs0ULAvs3jg",
        "outputId": "25302d84-1c4c-4ae0-a77c-c9c30179fd4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a sentence (default: 'though before his face I speak the words, Your'): \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'though before I face I speak the words, Your Your'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    }
  ]
}